# LinkedIn Scraper & Minimal Dashboard

> Usage interne uniquement. Respect strict des CGU LinkedIn. Ce projet fournit un worker de scraping d√©coupl√© d'un serveur FastAPI avec un mini dashboard pour visualiser les posts collect√©s. Le bouton manuel de d√©clenchement a √©t√© retir√© : on utilise d√©sormais `POST /trigger` (script / API) ou l'intervalle autonome / worker d√©di√©.

---
## üéØ Objectifs
- Scraping de posts LinkedIn √† partir de mots-cl√©s cibl√©s (recherche)
- Stockage principal MongoDB (Atlas), fallback automatique SQLite ou CSV
- Worker asynchrone (s√©par√© du serveur) + file/queue Redis pour jobs
- Dashboard FastAPI minimal (table pagin√©e + stats) ‚Äî plus de bouton de d√©clenchement dans l'UI
- Cache TTL & verrou anti-concurrence pour √©viter sur-scraping
- Logging structur√© JSON + rotation + m√©triques Prometheus `/metrics`
- Tests unitaires (pytest), linting Ruff, format Black, typage mypy
- Docker multi-stage pr√™t pour d√©ploiement serveur Linux (Playwright install√©)

---
## üß± Architecture (vue d'ensemble)

Documentation compl√©mentaire :

- Architecture actuelle d√©taill√©e (snapshot pr√©‚Äërefactor) : `docs/ARCHITECTURE_CURRENT.md`
- Plan de refactor multi-sprints : `docs/REFRACTOR_PLAN.md`

```
project/
‚îÇ-- scraper/
‚îÇ   ‚îÇ-- bootstrap.py      # Initialisation context: settings, clients, logging
‚îÇ   ‚îÇ-- utils.py          # Outils communs (UA random, parse date, langue, etc.)
‚îÇ   ‚îÇ-- worker.py         # Logique scraping + retries + stockage + screenshots
‚îÇ-- server/
‚îÇ   ‚îÇ-- main.py           # App FastAPI, montage routes, middlewares, metrics
‚îÇ   ‚îÇ-- routes.py         # Endpoints API + dashboard HTML
‚îÇ   ‚îÇ-- templates/
‚îÇ   ‚îÇ    ‚îî‚îÄ dashboard.html# UI unique minimaliste
‚îÇ-- scripts/
‚îÇ   ‚îÇ-- run_once.py       # Lance un job de scraping isol√© (sans queue)
‚îÇ   ‚îÇ-- start_server.ps1  # D√©marrage serveur (Windows)
‚îÇ   ‚îÇ-- run_scraper.ps1   # D√©marrage worker (Windows)
‚îÇ-- tests/                # Tests unitaires & snapshots s√©lecteurs
‚îÇ-- Dockerfile
‚îÇ-- requirements.txt
‚îÇ-- .env.example
‚îÇ-- README.md
‚îÇ-- .gitignore
```

---

## ‚öôÔ∏è Flux Fonctionnel (mise √† jour sans bouton manuel)

1. L'utilisateur ouvre le dashboard ‚áí posts r√©els visibles (les posts d√©mo sont exclus) + stats.
2. Un job est lanc√© via :
   - `POST /trigger` (curl / script / Postman / console navigateur)
   - le worker autonome (`AUTONOMOUS_WORKER_INTERVAL_SECONDS > 0`)
   - un worker s√©par√© consommant Redis.
3. Worker ‚áí Playwright + session (`storage_state.json`).
4. Extraction + application des filtres stricts (langue, recrutement, auteur/permalink, France, exclusion job-seekers) sauf si relax√©s.
5. Stockage Mongo ou fallback; mise √† jour meta.
6. Logs + screenshots + m√©triques.
7. Dashboard rafra√Æchi via SSE (`/stream`) ou polling.

### D√©clenchement manuel (exemples)

PowerShell :

```powershell
Invoke-RestMethod -Method POST -Uri http://localhost:8000/trigger -Headers @{ 'X-Trigger-From'='manual' }
```

Python :

```python
import requests; requests.post('http://localhost:8000/trigger', headers={'X-Trigger-From':'manual'})
```

---
## üóÑÔ∏è Stockage

Ordre de priorit√© :

1. MongoDB (Motor + collection `posts` & `meta`) ‚Äì backend principal
2. SQLite (fichier local `fallback.sqlite3`) si Mongo indisponible
3. CSV (append dans `exports/fallback_posts.csv`) si SQLite √©choue

Sch√©ma persistant actuel (champs de score supprim√©s) :

```jsonc
{
  "_id": "hash(post_url|timestamp)",
  "keyword": "python ai",
  "author": "Nom Auteur",
  "author_profile": "https://www.linkedin.com/in/...",
  "company": "Entreprise XYZ", // si d√©tect√©e ou d√©riv√©e heuristiquement
  "text": "Contenu du post...",
  "language": "fr",
  "published_at": "2025-09-18T08:21:00Z",
  "collected_at": "2025-09-18T08:25:12Z",
  "permalink": "https://www.linkedin.com/feed/update/urn:li:activity:XXXX/",
  "raw": { /* fragments bruts pour debug */ }
}
```

---
 
## üîí S√©curit√© & Conformit√©

- Variables sensibles uniquement via `.env` (jamais commit) : credentials, URIs
- Aucune redistribution publique des donn√©es collect√©es
- Respect des limitations implicites (sleep jitter, random UA)
- Possibilit√© de d√©sactiver le scraping global via variable `SCRAPING_ENABLED=0`
- Option d'activer une auth basique interne (`INTERNAL_AUTH_USER/PASS`)
- Jeton de protection d√©clenchement job (`TRIGGER_TOKEN`) activ√© si d√©fini : envoyer le header `X-Trigger-Token: <valeur>` sur `POST /trigger`
- HTTPS g√©r√© en amont (reverse proxy) ‚Äî possibilit√© future d'ajouter TLS local

---
 
## üì¶ Variables d'environnement (voir `.env.example`)

| Variable | Description | Exemple |
|----------|-------------|---------|
| `MONGO_URI` | URI MongoDB Atlas | `mongodb+srv://user:pass@cluster/db` |
| `MONGO_DB` | Nom DB | `linkedin_scrape` |
| `REDIS_URL` | Redis queue/cache | `redis://localhost:6379/0` |
| `SCRAPE_KEYWORDS` | Liste mots-cl√©s (s√©par√©s par ;) | `python;ai;data` |
| `SCRAPING_ENABLED` | 1/0 activer d√©sactiver | `1` |
| `PLAYWRIGHT_HEADLESS` | Mode headless | `1` |
| `CACHE_TTL_SECONDS` | TTL cache en secondes | `300` |
| `LOCK_FILE` | Fichier de verrou | `.scrape.lock` |
| `INTERNAL_AUTH_USER` | (Optionnel) utilisateur dashboard | `admin` |
| `INTERNAL_AUTH_PASS_HASH` | Hash bcrypt si activ√© | `$2b$...` |
| `LOG_LEVEL` | Niveau logs | `INFO` |
| `MAX_POSTS_PER_KEYWORD` | Limite extraction par mot-cl√© | `30` |
| `JOB_VISIBILITY_TIMEOUT` | Timeout r√©apparition job (s) | `300` |
| `EXPORT_DIR` | Dossier exports CSV | `exports` |
| `RECRUITMENT_SIGNAL_THRESHOLD` | Seuil compteur m√©trique recrutement (champ non stock√©) | `0.35` |
| `SHUTDOWN_TOKEN` | Jeton requis pour POST `/shutdown` | `secret123` |
| `PLAYWRIGHT_FORCE_SYNC` | Force un mode Playwright synchrone (fallback thread) si `1` | `0` |
| `AUTO_ENABLE_MOCK_ON_PLAYWRIGHT_FAILURE` | Active automatiquement mode mock si lancement Playwright √©choue | `1` |
| `FORCE_PLAYWRIGHT_DISABLED` | Force d√©sactivation Playwright (scraping r√©el) et bascule mock | `0` |
| `PLAYWRIGHT_FAILURE_LOG` | Fichier JSONL des erreurs Playwright throttl√© | `playwright_failures.log` |
| `STORAGE_STATE_ENCRYPT` | Chiffrer `storage_state.json` sur disque (Fernet) | `1` |
| `STORAGE_STATE_KEY` | Cl√© base64 32 bytes pour Fernet (si chiffrement) | `gAAAA...` |
| `PURGE_MAX_AGE_DAYS` | Purge SQLite des posts plus vieux que X jours | `30` |
| `VACUUM_INTERVAL_HOURS` | Intervalle maintenance (purge+VACUUM) heures | `6` |
| `FILTER_RECRUITMENT_ONLY` | Ne conserver que les posts recrutement (>= seuil) | `1` |
| `FILTER_REQUIRE_AUTHOR_AND_PERMALINK` | Filtrer posts sans auteur/permalink | `1` |
| `PLAYWRIGHT_MOCK_MODE` | Mode simulation (aucune navigation r√©elle) | `0` |

---
 
## üöÄ D√©marrage Local (Windows PowerShell)

```powershell
python -m venv .venv
. .venv\Scripts\Activate.ps1
pip install -r requirements.txt
playwright install chromium
Copy-Item .env.example .env
# √âditer .env avec vos valeurs

# Lancer serveur API seul
uvicorn server.main:app --reload --port 8000

# Lancer worker seul
python scripts/run_worker.py

# Lancer serveur + worker ensemble (d√©mo rapide)
python scripts/run_all.py
```
Acc√©der au dashboard: <http://127.0.0.1:8000/>

D√©clencher manuellement un job (sans UI) :

```powershell
python scripts\run_once.py --keywords "python;ai"
```

---
 
## üê≥ Docker

Build & run :

```bash
docker build -t linkedin-scraper .
# Cr√©er un r√©seau si usage conteneurs Redis/Mongo
# docker network create internal_net

# Exemple (avec variables inline de test)
docker run --rm -p 8000:8000 --env-file .env linkedin-scraper
```
Le worker peut √™tre un second conteneur (m√™me image) avec commande override :

```bash
docker run --rm --env-file .env linkedin-scraper python -m scraper.worker
```
Pour Playwright dans Docker : Chromium install√© au build + d√©pendances system (voir `Dockerfile`).

---
 
## üß™ Qualit√© & Tests
Commandes :
```powershell
ruff check .
black --check .
pytest -q --asyncio-mode=auto --maxfail=1 --disable-warnings
mypy .
```
Couverture :
```powershell
pytest --cov=scraper --cov=server --cov-report=term-missing
```
Auto-fix format :
```powershell
ruff check . --fix
black .
```

### üî• Smoke Test (Mode Mock)

Objectif : valider rapidement que le pipeline (context ‚Üí job ‚Üí stockage ‚Üí meta) fonctionne sans navigateur r√©el.

Script : `scripts/smoke_test.py` (r√©utilis√© au lieu de cr√©er `smoke_mock.py`).

Pr√©‚Äërequis : `PLAYWRIGHT_MOCK_MODE=1` et quelques mots-cl√©s.

Ex√©cution PowerShell :

```powershell
$Env:PLAYWRIGHT_MOCK_MODE='1'
$Env:SCRAPE_KEYWORDS='python;data'
python scripts/smoke_test.py
```

Sortie attendue (logs) : entr√©e `smoke_test_summary` avec `posts>0`.

Codes de retour :

| Code | Signification |
|------|---------------|
| 0 | Succ√®s (‚â•1 post mock stock√©) |
| 2 | Ex√©cution ok mais 0 post (anormal en mock, investiguer filtres) |
| 3 | Exception inattendue |

Int√©gration CI recommand√©e : √©tape d√©di√©e avant suite compl√®te (rapide <15s). Exemple (GitHub Actions) :

```yaml
  - name: Smoke test
    run: |
      export PLAYWRIGHT_MOCK_MODE=1
      export SCRAPE_KEYWORDS='python;data'
      python scripts/smoke_test.py
```

Baseline dur√©e sera consign√©e dans `docs/REFRACTOR_PLAN.md` Sprint 1 lorsque mesur√©e.

---
 
## üìä Observabilit√©
| Aspect | D√©tails |
|--------|---------|
| Logs | JSON via `structlog`, enrichis `request_id`, niveau configurable `LOG_LEVEL` |
| Rotation | Handler `RotatingFileHandler` (variables ci‚Äëdessous) |
| Metrics | Endpoint `/metrics` (Prometheus) exposant compteurs & histogrammes |
| Screenshots | Captur√©s sur √©checs critiques Playwright dans `screenshots/` |
| Traces futures | OpenTelemetry (roadmap) |

 
### M√©triques expos√©es
| Nom | Type | Description |
|-----|------|-------------|
| `scrape_jobs_total` (label `status`) | Counter | Nombre de jobs trait√©s par statut |
| `scrape_posts_extracted_total` | Counter | Total de posts extraits (par job) |
| `scrape_duration_seconds` | Histogram | Dur√©e des jobs de scraping |
| `scrape_mock_posts_extracted_total` | Counter | Posts synth√©tiques g√©n√©r√©s (mode mock) |
| `scrape_storage_attempts_total` (labels `backend,result`) | Counter | Succ√®s/erreurs par backend (mongo/sqlite/csv) |
| `scrape_queue_depth` | Gauge | Profondeur actuelle de la file de jobs Redis |
| `scrape_job_failures_total` | Counter | Nombre de jobs √©chou√©s (exceptions) |
| `scrape_step_duration_seconds` (label `step`) | Histogram | Dur√©e de sous-√©tapes (mongo_insert, sqlite_insert, etc.) |
| `scrape_rate_limit_wait_seconds_total` | Counter | Secondes cumul√©es d'attente dues au rate limiting |
| `scrape_rate_limit_tokens` | Gauge | Jetons disponibles (bucket courant) |
| `api_rate_limit_rejections_total` | Counter | Requ√™tes API rejet√©es (limitation IP) |
| `scrape_scroll_iterations_total` | Counter | Nombre total d'it√©rations de scroll ex√©cut√©es |
| `scrape_extraction_incomplete_total` | Counter | Extractions arr√™t√©es (< `MIN_POSTS_TARGET`) |
| `scrape_recruitment_posts_total` | Counter | Posts d√©tect√©s recrutement |
| `scrape_filtered_posts_total` (label `reason`) | Counter | Posts rejet√©s (recruitment, author_perma, langue, domaine ...) |

Endpoints op√©rationnels additionnels :
| Endpoint | M√©thode | Description |
|----------|---------|-------------|
| `/health` | GET | Sant√© enrichie (ping Mongo, last_run, age, queue_depth, flags) |
| `/shutdown` | POST | Arr√™t contr√¥l√© (token + √©ventuellement basic auth) |
| `/debug/auth` | GET | Diagnostic session Playwright (storage_state, modes) |
| `/debug/last_batch` | GET | Derniers posts (auteur, company, keyword, timestamps) pour debug extraction |
| `/api/debug/raw_posts` | GET | Vue brute SQLite (inclure d√©mo: `?include_demo=1`) |
| `/admin/filters/relax` | POST | Bypass filtres stricts extraction (d√©sactive langage/recrutement/auteur/permalink/France/job seekers) |
| `/admin/filters/strict` | POST | R√©active filtres stricts |
| `/admin/purge_demo_posts` | POST | Purge `demo_recruteur` + flags orphelins |
| `/api/stats` | GET | Statistiques runtime agr√©g√©es (mock_mode, intervalle autonome, posts_count, √¢ge last_run, queue_depth) |
| `/api/version` | GET | M√©tadonn√©es build (commit, timestamp) pour tra√ßabilit√© |
| `/metrics.json` | GET | Fallback JSON si Prometheus non consommable (mode d√©mo / sandbox) |
| `/debug/mode` | GET | Indique mode courant (mock, async, sync) |
| `/debug/storage/counts` | GET | Compteurs stockage SQLite (lignes) |
| `/debug/status` | GET | Statut synth√©tique (quotas, mode, risques) |

### Statistiques suppl√©mentaires (meta)
Le document meta Mongo (`_id: "global"`) contient d√©sormais :
```jsonc
{
  "posts_count": 1234,
  "last_run": "2025-09-19T09:10:11.123456+00:00",
  "last_job_posts": 42,
  "last_job_unknown_authors": 5,
  "last_job_unknown_ratio": 0.119,
  "scraping_enabled": true
}
```
Ces champs apparaissent partiellement dans `/health` : `last_job_unknown_authors`, `last_job_posts`, `last_job_unknown_ratio` pour rapidement suivre la qualit√© de d√©tection auteur.

### Capture d'authentification
Un screenshot `screenshots/auth_state.png` est g√©n√©r√© √† chaque tentative d'initialisation de session (utile si auteurs restent `Unknown`).

### Variables de configuration Logging
| Variable | R√¥le | Exemple |
|----------|------|---------|
| `LOG_FILE` | Active la sortie fichier si d√©fini | `logs/app.log` |
| `LOG_MAX_BYTES` | Taille max d'un fichier avant rotation | `2000000` |
| `LOG_BACKUP_COUNT` | Nombre de fichiers conserv√©s | `5` |

### Contexte de configuration
Les settings utilisent d√©sormais `pydantic-settings` (Pydantic v2) ‚Äî `BaseSettings` ayant √©t√© d√©plac√© hors du core. Le chargement se fait automatiquement depuis `.env` + variables d'environnement.

---
## üîÅ Strat√©gie de Retry (Tenacity)
- Backoff exponentiel + jitter (al√©a contr√¥l√©) pour limiter les patterns d√©tectables
- Nombre de tentatives configurable (`MAX_RETRIES`)
- Erreurs transitoires encapsul√©es (ex: navigation timeouts) pour r√©essai cibl√©
- Extension future : circuit-breaker / compteur d'√©checs cons√©cutifs

---
## üß™ Tests Cl√©s Pr√©vus
| Test | Description |
|------|-------------|
| Selectors snapshot | V√©rifie structure DOM attendue / fallback si changement |
| Storage fallback | Simule indisponibilit√© Mongo ‚áí bascule SQLite/CSV |
| API pagination | V√©rification limites, pages vides |
| Queue job lifecycle | Insert ‚Üí consume ‚Üí ack timeout |
| Lock anti-concurrent | Double lancement worker refus√© |
| Lang detection | Multi-langue texte court/long |

---
## üß¨ Scores supprim√©s
Les champs `score` et `recruitment_score` ont √©t√© retir√©s du mod√®le persistant pour simplifier l'usage m√©tier. La logique de d√©tection recrutement subsiste uniquement comme incr√©ment de m√©trique `scrape_recruitment_posts_total`. Toute donn√©e legacy est migr√©e (SQLite) ou simplement ignor√©e (Mongo d√©j√† sans nouveau champ lors d'insertion). Aucune action manuelle requise.

---
## ‚öñÔ∏è Avertissement L√©gal & √âthique
- Ne pas surcharger LinkedIn (delais random + limites strictes)
- Ne pas republier / revendre le contenu extrait
- D√©sactiver imm√©diatement si modification CGU non compatible
- Stocker minimum de donn√©es n√©cessaires

---
## üó∫Ô∏è Roadmap Potentielle
- Int√©gration OpenTelemetry traces
- Export parquet / Data Lake
- Scheduling cron (APScheduler) au lieu d'appui manuel
- Support login rotation comptes
- D√©tection CAPTCHA & pause adaptative

---
## ü§ù Contributions Internes
1. Cr√©er branche feature
2. Ajouter tests + docs br√®ves
3. Lint & format avant PR
4. Revue par pair interne

---
## üßæ Licence
Usage interne priv√© (pas de distribution publique).

---
## ‚úÖ Statut
MVP fonctionnel livr√© : worker Playwright, stockage multi-niveaux, API & dashboard, m√©triques, logging structur√© + rotation, tests de base. Prochaines √©tapes optionnelles : durcir s√©lecteurs, enrichir CI/CD, ajout d'une strat√©gie anti-CAPTCHA.

---
## üåê D√©ploiement Gratuit / Low-Cost

Priorit√©: Deta Space (gratuit), sinon Render (Free plan) ou Railway (Free trial / low-cost). Le scraping r√©el continu avec Playwright n√©cessite un runtime supportant Chromium (Deta Space n'ex√©cute pas de navigateur complet de fa√ßon fiable) ‚áí mode mock recommand√© sur Deta Space.

### Variables Cl√©s de D√©ploiement
| Variable | R√¥le |
|----------|------|
| `PLAYWRIGHT_MOCK_MODE` | `1` pour donn√©es synth√©tiques (CI / Deta) ; `0` pour vrai scraping |
| `AUTONOMOUS_WORKER_INTERVAL_SECONDS` | Intervalle secondes entre cycles auto (ex: 900) |
| `INPROCESS_AUTONOMOUS` | `1` pour ex√©cuter le worker dans le m√™me process FastAPI (utile Deta) |
| `DASHBOARD_PUBLIC` | `1` rendu public, sinon activer auth interne |
| `MONGO_URI` | Connexion MongoDB Atlas (persistance) sinon fallback SQLite |
| `WORKER_RESTART_DELAY_SECONDS` | D√©lai red√©marrage worker d√©di√© (Render/Railway) |
| `PORT` | Port impos√© par la plateforme (Render/Railway) |
| `INTERNAL_AUTH_USER` | Active Basic Auth si d√©fini (toujours appliqu√© m√™me avec `DASHBOARD_PUBLIC=1`) |
| `INTERNAL_AUTH_PASS_HASH` | Hash bcrypt explicite si d√©j√† g√©n√©r√© |
| `INTERNAL_AUTH_PASS` | Mot de passe en clair (hash g√©n√©r√© automatiquement si HASH absent) |
| `STORAGE_STATE_B64` | Contenu base64 de `storage_state.json` inject√© au d√©marrage si fichier manquant |

### 1. Deta Space (Mock Mode Conseill√©)
1. Installer l'outil Deta & login.
2. Ajouter le `Spacefile` fourni √† la racine (d√©j√† pr√©sent).
3. D√©ployer: `deta space push`.
4. Dans l'interface Space, ajouter les variables d'environnement souhait√©es (ex: `PLAYWRIGHT_MOCK_MODE=1`, `INPROCESS_AUTONOMOUS=1`, `AUTONOMOUS_WORKER_INTERVAL_SECONDS=900`).
5. (Optionnel) Ajouter `MONGO_URI` vers un cluster Atlas pour persistance; sinon les donn√©es seront dans `fallback.sqlite3` interne (√©ph√©m√®re sur rebuilds).

Limitations Deta:
- Pas de navigateur Chrome complet stable ‚áí mode r√©el non garanti.
- Utiliser le mode mock pour d√©monstration du dashboard + SSE.

### 2. Render (Web + Worker s√©par√©s)
Fichiers utilis√©s: `render.yaml`, `Procfile`.
1. Cr√©er un nouveau Blueprint dans Render √† partir du repo (connect GitHub).
2. Render d√©tecte `render.yaml` et provisionne deux services :
  - Web: lance `python scripts/run_server.py` sur le port `$PORT`.
  - Worker: lance `python scripts/run_worker.py` avec red√©marrage automatique.
3. Dans l'onglet Environment, ajouter (exemple r√©el minimal):
  - `MONGO_URI=...` (Atlas)
  - `PLAYWRIGHT_MOCK_MODE=0`
  - `STORAGE_STATE_B64=<base64 du storage_state.json>` (ou montez le fichier via volume priv√©)
  - `INTERNAL_AUTH_USER=admin` + `INTERNAL_AUTH_PASS=ChangeMe!` (hash auto)
  - `AUTONOMOUS_WORKER_INTERVAL_SECONDS=0` (si worker d√©di√© s√©par√©) ou >0 si vous supprimez le service worker.
  - (Optionnel) `DASHBOARD_PUBLIC=1` pour acc√®s sans auth si aucune variable INTERNAL_AUTH_*.
4. (Optionnel) Ajouter un Redis manag√©. Sinon le worker autonome tournant p√©riodiquement suffit.
5. Fournir la session: soit via `STORAGE_STATE_B64`, soit en attachant apr√®s d√©ploiement un fichier `storage_state.json`. Le bootstrap d√©codera automatiquement la variable si le fichier est absent.

SSE: Render supporte les connexions persistantes HTTP/1.1 ‚áí `/stream` fonctionne.

### 3. Railway
1. Rails nouveau projet ‚Üí connecter repository.
2. Ajouter deux services manuels si souhait√©: `web` (FastAPI) & `worker` (m√™me image, commande diff√©rente) ou un seul service avec `INPROCESS_AUTONOMOUS=1`.
3. Dans Variables, d√©finir valeurs analogues √† Render.
4. S'assurer d'installer Playwright dans postinstall (ex: `nixpacks` build d√©tecte requirements puis ajouter hook: `python -m playwright install --with-deps chromium`).

### 4. Docker Compose (Auto- h√©bergement VPS)
Utiliser `docker-compose.yml` existant: un service API + un worker + Redis + Mongo si souhait√©. Adapter `.env`.

### 5. Authentification & Public
- D√©mo publique: `DASHBOARD_PUBLIC=1`, laisser `INTERNAL_AUTH_USER` vide.
- Production interne: `DASHBOARD_PUBLIC=0` puis d√©finir `INTERNAL_AUTH_USER` + `INTERNAL_AUTH_PASS_HASH`.

### 6. Fournir `storage_state.json`
Scraping r√©el LinkedIn n√©cessite une session authentifi√©e:
1. En local: lancer `playwright codegen https://www.linkedin.com/feed/` ou navigation manuelle via script pour login.
2. Exporter storage state: adapter un petit script Playwright pour sauvegarder `storage_state.json`.
3. Ne jamais committer ce fichier. Le fournir √† l'environnement (ex: Render) via un secret base64:
  - Encoder (PowerShell): `Set-Content -Path storage_state.b64 -Value ([Convert]::ToBase64String([IO.File]::ReadAllBytes('storage_state.json')))`
  - Encoder (Linux/macOS): `base64 -w0 storage_state.json > storage_state.b64`
  - Variable: `STORAGE_STATE_B64=<contenu du fichier .b64>`
  - Le bootstrap d√©code automatiquement si `storage_state.json` est absent.

### 6bis. Basic Auth l√©g√®re m√™me en mode public
Si `DASHBOARD_PUBLIC=1` mais que vous d√©finissez `INTERNAL_AUTH_USER` + ( `INTERNAL_AUTH_PASS_HASH` ou `INTERNAL_AUTH_PASS` ):
- CORS large activ√© (acc√®s JS depuis ailleurs) mais endpoints prot√©g√©s par Basic Auth.
- Utiliser un header: `Authorization: Basic base64(user:password)`.
- Pour √©viter stocker un hash manuellement: mettre `INTERNAL_AUTH_PASS=monmotdepasse` et laisser vide `INTERNAL_AUTH_PASS_HASH`.


### 7. Mode Autonome In-Process
Activez `INPROCESS_AUTONOMOUS=1` et `AUTONOMOUS_WORKER_INTERVAL_SECONDS>0`. Le serveur FastAPI d√©marrera une t√¢che asynchrone de scraping p√©riodique (m√™me logique que le worker) ‚Äî utile quand la plateforme ne permet pas de process s√©par√©.

### 8. Export CSV Minimal
```
python scripts/export_csv.py --out exports/posts_snapshot.csv --limit 1000
```
Colonne: `_id, keyword, author, company, text, language, published_at, collected_at, permalink`.

### 9. Surveillance / Fiabilit√©
- Red√©marrage worker automatique (script `run_worker.py`) ‚Üí log en stdout sur crash.
- M√©triques Prometheus (`/metrics`) : v√©rifier `scrape_jobs_total`, `scrape_post_extracted_total`, `scrape_recruitment_posts_total`.
- SSE temps r√©el: navigateur √©coute `/stream` (√©v√©nements `job_complete`, `toggle`).

### 10. Plans d'√©volution Cloud
| Besoin | Option |
|--------|--------|
| Multi-instance / scaling | Redis externe pour queue + cache rate limit |
| Observabilit√© avanc√©e | Ajouter OpenTelemetry + exporter traces |
| Persist de session Playwright | Stocker storage_state chiffr√© (KMS) |
| Anti blocage | Proxy rotatif / user-agents dynamiques |

---

### Note Playwright (r√©seau / proxy interne)
Si l'installation du navigateur √©choue avec une erreur de certificat (`SELF_SIGNED_CERT_IN_CHAIN`) :
1. V√©rifier le proxy d'entreprise (ex: config syst√®me / variables `HTTP_PROXY` / `HTTPS_PROXY`).
2. Ajouter le certificat racine interne dans le magasin syst√®me.
3. En dernier recours (non recommand√© long terme) :
  ```powershell
  setx NODE_TLS_REJECT_UNAUTHORIZED 0
  # puis dans un nouveau terminal
  python -m playwright install chromium
  ```
4. Pour CI sans navigateur : utiliser `PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD=1` puis installer au runtime contr√¥l√©.

Retirer la d√©sactivation TLS aussit√¥t que la cha√Æne de confiance est corrig√©e.

---

> Prochain fichier sugg√©r√© : `.env.example` ou squelette code (`bootstrap.py`). Dis-moi si on poursuit.

---
### üîó Documentation Technique Additionnelle
- Snapshot architecture courante : `docs/ARCHITECTURE_CURRENT.md`
- Roadmap refactor : `docs/REFRACTOR_PLAN.md`

---
### ‚ÑπÔ∏è Endpoint `/api/stats`
Expose un sous-ensemble d'informations runtime pratiques pour monitoring l√©ger (diff√©rent de `/health`):
```jsonc
{
  "playwright_mock_mode": false,
  "autonomous_interval": 0,
  "scraping_enabled": true,
  "keywords_count": 3,
  "mongo_connected": true,
  "redis_connected": false,
  "posts_count": 124,
  "last_run": "2025-09-19T09:10:11.123456+00:00",
  "last_run_age_seconds": 42,
  "queue_depth": 0
}
```
Utilisation: supervision simple (dashboards externes) sans parser les m√©triques Prometheus.

### üîê Hash Bcrypt automatique
Si vous d√©finissez `INTERNAL_AUTH_PASS` (sans `INTERNAL_AUTH_PASS_HASH`) le hash est g√©n√©r√© au d√©marrage via passlib (bcrypt==3.2.2). Pour changer le mot de passe en production, red√©ployer avec la nouvelle valeur ou basculer sur un hash explicite.

### üè∑Ô∏è Endpoint `/api/version`
Expose des m√©tadonn√©es de build pour v√©rifier rapidement la version d√©ploy√©e.
Variables attendues (optionnelles) inject√©es au d√©ploiement:
```bash
APP_COMMIT=abc1234           # SHA git court ou complet
BUILD_TIMESTAMP=2025-09-19T12:34:56Z
```
R√©ponse typique:
```jsonc
{
  "app_commit": "abc1234",
  "build_timestamp": "2025-09-19T12:34:56Z",
  "playwright_mock_mode": false
}
```
Sans injection, les valeurs retournent `"unknown"`. Utile pour dashboards l√©gers ou v√©rifier qu‚Äôun redeploy a bien pris effet.

---
## üß∞ Automations & Tooling Ajout√©s

### CI (GitHub Actions)
Workflow `ci.yml` : lint (ruff), format check (black), mypy, tests Pytest + couverture. Badge (√† ajouter apr√®s push sur branche principale) :
```
![CI](https://github.com/<org>/<repo>/actions/workflows/ci.yml/badge.svg)
```

### Docker Compose
Fichier `docker-compose.yml` fourni :
```bash
docker compose up -d --build
# API: http://localhost:8000  | Mongo: 27017 | Redis: 6379
```
Le service `api` lance FastAPI (scraping d√©sactiv√©), le service `worker` ex√©cute le scraping.

### Script PowerShell `tasks.ps1`
Charger et lister :
```powershell
. .\tasks.ps1
Invoke-Task setup      # venv + deps + playwright
Invoke-Task lint       # ruff + mypy
Invoke-Task format     # ruff --fix + black
Invoke-Task test       # pytest
Invoke-Task coverage   # couverture
Invoke-Task server     # uvicorn
Invoke-Task worker     # worker loop
Invoke-Task compose-up # stack docker
Invoke-Task compose-down
```

### Mode Mock (Sans Navigateur)
Activer un mode de g√©n√©ration synth√©tique de posts pour tests rapides ou CI sans Playwright :
```
PLAYWRIGHT_MOCK_MODE=1
SCRAPING_ENABLED=1
```
Effets :
- `process_keyword` retourne jusqu'√† 5 posts synth√©tiques par mot-cl√© sans ouvrir Chromium.
- Champs `raw.mode = "mock"` pour tra√ßabilit√©.
- Id√©al pour valider pipeline stockage / API sans r√©seau externe.
Limites : pas de v√©rification de s√©lecteurs ni r√©alisme de contenu.

### Gestion des posts de d√©monstration
- Les posts dont `author` ou `keyword` == `demo_recruteur` sont exclus de `/api/posts` et du dashboard.
- Diagnostics expose `sqlite.demo_posts`, `sqlite.real_posts`, `sqlite.only_demo`.
- Inspection brute : `/api/debug/raw_posts?include_demo=1`.
- Purge : `python scripts/purge_mock_posts.py --purge` ou `POST /admin/purge_demo_posts`.

### Premier cycle r√©el (checklist)
1. Purger contenu d√©mo (voir ci-dessus).
2. (Option) Relaxer filtres: `POST /admin/filters/relax`.
3. `POST /trigger`.
4. V√©rifier `/diagnostics.json` ‚Üí `real_posts > 0`.
5. `POST /admin/filters/strict`.

### Toggle runtime filtres
```text
POST /admin/filters/relax   # PLAYWRIGHT_DISABLE_STRICT_FILTERS=1
POST /admin/filters/strict  # PLAYWRIGHT_DISABLE_STRICT_FILTERS=0
```
Flag visible dans diagnostics (`filters_relaxed`); posts relax√©s portent `raw.filters_bypassed=1`.

### Purge script / endpoint
Script:
```powershell
python scripts/purge_mock_posts.py          # dry-run
python scripts/purge_mock_posts.py --purge  # suppression
```
Endpoint:
```powershell
Invoke-RestMethod -Method POST http://localhost:8000/admin/purge_demo_posts
```
R√©ponse: `{ removed, orphan_flags, duration_seconds }`.

Personnalisation :
`MAX_MOCK_POSTS` limite configurable (par d√©faut 5). M√©trique associ√©e : `scrape_mock_posts_extracted_total`.

### Concurrency & Rate Limiting (Nouveaut√©s)
Variables :
```
CONCURRENCY_LIMIT=2            # Nombre max de jobs simultan√©s
PER_KEYWORD_DELAY_MS=500       # D√©lai entre deux mots-cl√©s dans un m√™me job
GLOBAL_RATE_LIMIT_PER_MIN=120  # Limite douce (placeholder token bucket simple)
```
Objectifs : r√©duire bursts, pr√©parer extension vers un vrai seau de jetons distribu√©.
La m√©trique `scrape_queue_depth` permet de surveiller l'accumulation des jobs.

### API Rate Limit (IP In-Memory)
Param√®tres :
```
API_RATE_LIMIT_PER_MIN=60
API_RATE_LIMIT_BURST=20
```
Limitation de base par IP (LRU ~512 IP). √Ä distribuer via Redis pour d√©ploiements multi-instances. M√©trique de rejet: `api_rate_limit_rejections_total`.

### Token Bucket (Rate Limit R√©el)
### Scrolling & Compl√©tude (Nouveaut√©s)
Nouveaux param√®tres pour affiner l'extraction progressive des r√©sultats paresseusement charg√©s :
```
MAX_SCROLL_STEPS=5      # Limite dure d'it√©rations de scroll suppl√©mentaires
SCROLL_WAIT_MS=1200     # Attente (ms) apr√®s chaque scroll pour laisser charger le DOM
MIN_POSTS_TARGET=10     # Seuil minimal de posts avant d'accepter un arr√™t anticip√©
```
Logique d'arr√™t :
1. Posts >= `MAX_POSTS_PER_KEYWORD` ‚áí stop
2. Posts >= `MIN_POSTS_TARGET` ET aucune augmentation apr√®s une it√©ration ‚áí stop
3. `MAX_SCROLL_STEPS` atteint ‚áí stop (marqu√© incomplete si < seuil)

M√©triques associ√©es :
- `scrape_scroll_iterations_total` : incr√©ment√©e √† chaque scroll tent√©
- `scrape_extraction_incomplete_total` : incr√©ment si extraction < `MIN_POSTS_TARGET` en fin de boucle

Objectif : instrumenter la ¬´ profondeur ¬ª requise pour atteindre la compl√©tude et calibrer les valeurs par environnement (CI vs prod restreinte).

Param√®tres :
```
RATE_LIMIT_BUCKET_SIZE=120      # Capacit√© maximale (burst autoris√©)
RATE_LIMIT_REFILL_PER_SEC=2.0   # D√©bit de r√©g√©n√©ration
```
Fonctionnement : avant chaque mot-cl√© le worker consomme 1 jeton. Si insuffisant ‚áí attente calcul√©e (deficit / refill_per_sec) mesur√©e dans `scrape_rate_limit_wait_seconds_total`. Le gauge `scrape_rate_limit_tokens` refl√®te l'√©tat du bucket.

---
## üéØ D√©tection Signal Recrutement (Nouveaut√©)
Objectif : identifier les posts susceptibles d'√™tre des signaux de recrutement (annonce explicite, sourcing, besoins √©quipe, ouverture de poste) dans les domaines juridiques / fiscaux / data / tech.

### Heuristique
La fonction `compute_recruitment_signal(text)` applique :
1. Normalisation (lowercase, accents retir√©s, ponctuation simplifi√©e)
2. Tokenisation + stemming tr√®s l√©ger (suffixes fran√ßais usuels)
3. Pond√©ration :
   - Mots/lemmes indicateurs (ex: `recrut`, `poste`, `hiring`, `rejoindre`, `talent`, `cdi`, `alternance`) ‚áí poids individuel
   - Phrases cl√©s (bigrammes / trigrammes) comme `nous recrutons`, `on recrute`, `offre d emploi`, `recherche son/sa`, `hiring for`, `join our team` ‚áí bonus suppl√©mentaire
4. Score brut liss√© et clamp√© dans [0,1] (log / normalisation longueur pour √©viter sur-pond√©ration de r√©p√©titions).

### Seuil & M√©trique
- Le seuil configur√© via `RECRUITMENT_SIGNAL_THRESHOLD` (ex: 0.35) d√©termine l'incr√©ment de la m√©trique `scrape_recruitment_posts_total`.
- Tous les posts stockent de toute fa√ßon `recruitment_score` (nullable si ancienne donn√©e ou mode legacy).

### Filtrage Dashboard & API
- Dashboard : champ num√©rique "Score recrutement ‚â•" (query param `min_score`).
- API `/api/posts?min_score=0.4` renvoie uniquement les posts dont `recruitment_score` ‚â• valeur.
  - Si `min_score` absent ‚áí pas de filtrage.

### Stockage & Compatibilit√©
- Mongo : champ `recruitment_score` ajout√© dans chaque document (nullable).
- SQLite : colonne ajout√©e automatiquement si base cr√©√©e apr√®s la fonctionnalit√©; pour une base existante ex√©cuter :
  ```sql
  ALTER TABLE posts ADD COLUMN recruitment_score REAL;
  ```
  (Optionnel : laisser NULL pour historiques.)
- CSV : nouvelle colonne `recruitment_score` apr√®s `score`.

### Tests
`tests/test_recruitment_scoring.py` couvre :
- Bas niveau sur texte neutre (score faible)
- Texte riche en signaux (score √©lev√©)
- Stabilit√© du domaine [0,1]

### Ajustements Futurs (Id√©es)
- Pond√©ration contextuelle (ex: pr√©sence d'un lien vers une offre)
- D√©tection langue + mapping lexiques multi-langues
- Mod√®le ML l√©ger (TF-IDF / logreg) si corpus √©tiquet√© interne disponible
- D√©corr√©lation bruit marketing vs. v√©ritables annonces via pattern n√©gatifs

---

---
## üîÑ Fallback Storage Test√©
Un test (`tests/test_fallback_storage.py`) v√©rifie :
1. Insertion SQLite quand Mongo absent.
2. Fallback CSV forc√© en simulant une erreur SQLite.

---
## üß™ Configuration Lint & Type
Fichiers ajout√©s : `ruff.toml`, `mypy.ini` pour coh√©rence multi-environnements.

