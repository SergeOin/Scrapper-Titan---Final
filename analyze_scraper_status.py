#!/usr/bin/env python3
"""Analyse l'√©tat du scraper et diagnostique les probl√®mes potentiels."""

import sqlite3
import os
from datetime import datetime, timedelta

DB_PATH = "fallback.sqlite3"

def analyze_database():
    """Analyse l'√©tat de la base de donn√©es."""
    print("=" * 60)
    print("ANALYSE DE L'√âTAT DU SCRAPER")
    print("=" * 60)
    
    if not os.path.exists(DB_PATH):
        print(f"‚ùå Base de donn√©es non trouv√©e: {DB_PATH}")
        return
    
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    
    # Stats g√©n√©rales
    cur.execute("SELECT COUNT(*) FROM posts")
    total = cur.fetchone()[0]
    print(f"\nüìä STATISTIQUES G√âN√âRALES:")
    print(f"   Total posts en base: {total}")
    
    # Posts r√©cents (utiliser collected_at)
    cur.execute("SELECT COUNT(*) FROM posts WHERE collected_at > datetime('now', '-1 hour')")
    last_hour = cur.fetchone()[0]
    cur.execute("SELECT COUNT(*) FROM posts WHERE collected_at > datetime('now', '-10 minutes')")
    last_10min = cur.fetchone()[0]
    cur.execute("SELECT COUNT(*) FROM posts WHERE collected_at > datetime('now', '-1 day')")
    last_day = cur.fetchone()[0]
    
    print(f"   Posts derni√®res 10 min: {last_10min}")
    print(f"   Posts derni√®re heure: {last_hour}")
    print(f"   Posts dernier jour: {last_day}")
    
    # Dernier post ajout√©
    cur.execute("SELECT collected_at, SUBSTR(text, 1, 100) FROM posts ORDER BY collected_at DESC LIMIT 1")
    row = cur.fetchone()
    if row:
        print(f"\nüìù DERNIER POST:")
        print(f"   Date: {row[0]}")
        print(f"   Aper√ßu: {row[1]}...")
    
    # Analyse des rejets possibles (posts sans contenu juridique)
    print(f"\nüîç ANALYSE DU FILTRAGE JURIDIQUE:")
    
    # Compter les posts avec mots-cl√©s juridiques
    legal_keywords = ['avocat', 'juriste', 'juridique', 'notaire', 'droit', 'contrat', 'CDI', 'CDD', 
                      'recrute', 'recrutement', 'poste', 'embauche', 'opportunit√©']
    
    for kw in ['avocat', 'juriste', 'juridique', 'recrute', 'CDI', 'CDD']:
        cur.execute(f"SELECT COUNT(*) FROM posts WHERE LOWER(text) LIKE ?", (f'%{kw.lower()}%',))
        count = cur.fetchone()[0]
        print(f"   Posts contenant '{kw}': {count}")
    
    # V√©rifier si le filtre est trop strict
    print(f"\n‚öôÔ∏è TEST DU FILTRE ACTUEL:")
    
    # R√©cup√©rer les 10 derniers posts pour test
    cur.execute("SELECT id, text FROM posts ORDER BY collected_at DESC LIMIT 10")
    recent_posts = cur.fetchall()
    
    conn.close()
    
    # Tester le filtre sur ces posts
    try:
        from scraper.legal_filter import is_legal_job_post, FilterConfig
        
        config = FilterConfig()
        passed = 0
        failed = 0
        
        print(f"\n   Test sur les {len(recent_posts)} derniers posts:")
        for post_id, text in recent_posts:
            if not text:
                print(f"   ‚ö†Ô∏è Post {post_id}: contenu vide")
                continue
            result = is_legal_job_post(text, config=config)
            if result.is_valid:
                passed += 1
                status = "‚úÖ"
            else:
                failed += 1
                status = "‚ùå"
            
            preview = text[:60].replace('\n', ' ') if text else "N/A"
            print(f"   {status} Post {post_id}: {preview}...")
            if not result.is_valid:
                reason = result.get_rejection_reason() if hasattr(result, 'get_rejection_reason') else result.exclusion_reason
                print(f"      Raison: {reason}")
        
        print(f"\n   üìà R√©sultat: {passed}/{len(recent_posts)} posts passent le filtre")
        
        if passed == 0 and len(recent_posts) > 0:
            print("\n   ‚ö†Ô∏è ATTENTION: Aucun post ne passe le filtre!")
            print("   Le filtre est peut-√™tre trop strict.")
            
            # Analyser les raisons de rejet
            print("\n   üìã ANALYSE D√âTAILL√âE DES REJETS:")
            for post_id, text in recent_posts[:3]:
                if not text:
                    continue
                print(f"\n   --- Post {post_id} ---")
                result = is_legal_job_post(text, config=config)
                print(f"   Score l√©gal: {result.legal_score:.2f}")
                print(f"   Score recrutement: {result.recruitment_score:.2f}")
                print(f"   Agence de recrutement: {result.is_agency}")
                reason = result.get_rejection_reason() if hasattr(result, 'get_rejection_reason') else result.exclusion_reason
                print(f"   Raison rejet: {reason}")
                
    except Exception as e:
        print(f"   ‚ùå Erreur lors du test du filtre: {e}")
        import traceback
        traceback.print_exc()

def check_scraper_process():
    """V√©rifie si le scraper tourne."""
    print(f"\nüîÑ PROCESSUS SCRAPER:")
    try:
        import subprocess
        result = subprocess.run(['tasklist', '/FI', 'IMAGENAME eq python.exe'], 
                              capture_output=True, text=True)
        if 'python.exe' in result.stdout:
            print("   ‚úÖ Python est en cours d'ex√©cution")
        else:
            print("   ‚ùå Aucun processus Python d√©tect√©")
    except Exception as e:
        print(f"   ‚ùì Impossible de v√©rifier: {e}")

def check_session():
    """V√©rifie l'√©tat de la session LinkedIn."""
    print(f"\nüîê SESSION LINKEDIN:")
    if os.path.exists("storage_state.json"):
        stat = os.stat("storage_state.json")
        mod_time = datetime.fromtimestamp(stat.st_mtime)
        age = datetime.now() - mod_time
        print(f"   Fichier session: storage_state.json")
        print(f"   Derni√®re modification: {mod_time}")
        print(f"   √Çge: {age}")
        if age > timedelta(hours=24):
            print("   ‚ö†Ô∏è Session peut-√™tre expir√©e (> 24h)")
    else:
        print("   ‚ùå Pas de fichier de session trouv√©")

if __name__ == "__main__":
    analyze_database()
    check_scraper_process()
    check_session()
    print("\n" + "=" * 60)
